# CS224N WINTER 2022

----

[toc]



----
## lecture 9 Transformers

### slides

[[slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture09-transformers.pdf)] 

### suggested readings

1. （[Project Handout (IID SQuAD track)](http://web.stanford.edu/class/cs224n/project/default-final-project-handout-squad-track.pdf)）
2. （[Project Handout (Robust QA track)](http://web.stanford.edu/class/cs224n/project/default-final-project-handout-robustqa-track.pdf)）
3. （[Attention Is All You Need](https://arxiv.org/abs/1706.03762.pdf)）
4. （[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)）
5. （[Transformer (Google AI blog post)](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)）
6. （[Layer Normalization](https://arxiv.org/pdf/1607.06450.pdf)）
7. （[Image Transformer](https://arxiv.org/pdf/1802.05751.pdf)）
8. （[Music Transformer: Generating music with long-term structure](https://arxiv.org/pdf/1809.04281.pdf)）

----
## lecture 10 更多关于Transformers的内容以及预训练

### slides

[[slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture10-pretraining.pdf)]      

### suggested readings

1. （[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)）
2. （[Contextual Word Representations: A Contextual Introduction](https://arxiv.org/abs/1902.06006.pdf)）
3. （[The Illustrated BERT, ELMo, and co.](http://jalammar.github.io/illustrated-bert/)）
4. （[Martin & Jurafsky Chapter on Transfer Learning](https://web.stanford.edu/~jurafsky/slp3/11.pdf)）

### huggingface transformers tutorial session

[[Colab](https://colab.research.google.com/drive/1pxc-ehTtnVM72-NViET_D2ZqOlpOi2LH?usp=sharing)]

### assignment5 参考答案

[[code](http://web.stanford.edu/class/cs224n/assignments/a5.zip)] [[handout](http://web.stanford.edu/class/cs224n/assignments/a5.pdf)] [[latex template](http://web.stanford.edu/class/cs224n/assignments/a5_latex.zip)]    



----
## lecture 11 问答系统

### slides

[[slides](http://web.stanford.edu/class/cs224n/slides/Danqi-QA-slides-2022.pdf)]     

### notes

[[notes](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes07-QA.pdf)]

### suggested readings

1. （[SQuAD: 100,000+ Questions for Machine Comprehension of Text](https://arxiv.org/pdf/1606.05250.pdf)）
2. （[Bidirectional Attention Flow for Machine Comprehension](https://arxiv.org/pdf/1611.01603.pdf)）
3. （[Reading Wikipedia to Answer Open-Domain Questions](https://arxiv.org/pdf/1704.00051.pdf)）
4. （[Latent Retrieval for Weakly Supervised Open Domain Question Answering](https://arxiv.org/pdf/1906.00300.pdf)）
5. （[Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/pdf/2004.04906.pdf)）
6. （[Learning Dense Representations of Phrases at Scale](https://arxiv.org/pdf/2012.12624.pdf)）

----
## lecture 12 自然语言生成

### slides

[[slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture12-generation-final.pdf)]

### suggested readings

1. （[The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751.pdf)）
2. （[Get To The Point: Summarization with Pointer-Generator Networks](https://arxiv.org/abs/1704.04368.pdf)）
3. （[Hierarchical Neural Story Generation](https://arxiv.org/abs/1805.04833.pdf)）
4. （[How NOT To Evaluate Your Dialogue System](https://arxiv.org/abs/1603.08023.pdf)）

----
## lecture 13 将知识集成到语言模型

### slides

[[slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture-knowledge.pdf)]

### suggested readings

1. （[ERNIE: Enhanced Language Representation with Informative Entities](https://arxiv.org/pdf/1905.07129.pdf)）
2. （[Barack’s Wife Hillary: Using Knowledge Graphs for Fact-Aware Language Modeling](https://arxiv.org/pdf/1906.07241.pdf)）
3. （[Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model](https://arxiv.org/pdf/1912.09637.pdf)）
4. （[Language Models as Knowledge Bases?](https://www.aclweb.org/anthology/D19-1250.pdf)）

### project milestone

[[Instructions](http://web.stanford.edu/class/cs224n/project/CS224N_Final_Project_Milestone_Instructions.pdf)]

----
## lecture 14 偏见，毒性与公正

### suggested readings

1. （[The Risk of Racial Bias in Hate Speech Detection](https://homes.cs.washington.edu/~msap/pdfs/sap2019risk.pdf)）
2. （[Social Bias Frames](https://homes.cs.washington.edu/~msap/social-bias-frames/)）
3. （[PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction](https://arxiv.org/abs/2010.13816)）

----
## lecture 15 检索增强模型+知识

### slides

[[slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture15-guu.pdf)]

### suggested readings

1. （[Locating and Editing Factual Knowledge in GPT](https://arxiv.org/abs/2202.05262)）
2. （[LaMDA: Language Models for Dialog Applications](https://arxiv.org/abs/2201.08239)）
3. （[REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909)）

----
## lecture 16 卷积网络，树递归神经网络，成分分析

### slides

[[slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture16-CNN-TreeRNN.pdf)]

### suggested readings

1. （[Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882.pdf)）
2. （[Improving neural networks by preventing co-adaptation of feature detectors](https://arxiv.org/abs/1207.0580)）
3. （[A Convolutional Neural Network for Modelling Sentences](https://arxiv.org/pdf/1404.2188.pdf)）
4. （[Parsing with Compositional Vector Grammars.](http://www.aclweb.org/anthology/P13-1045)）
5. （[Constituency Parsing with a Self-Attentive Encoder](https://arxiv.org/pdf/1805.01052.pdf)）

----
## lecture 17 大模型的正则化法则

### suggested readings

[Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)

----
## lecture 18 共指关系

### slides

[[slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture18-coref.pdf)]

### suggested readings

1. （[Coreference Resolution Chapter from Jurafsky and Martin](https://web.stanford.edu/~jurafsky/slp3/21.pdf)）
2. （[End-to-end Neural Coreference Resolution](https://arxiv.org/pdf/1707.07045.pdf)）

----

## lecture 19 编辑神经网络

### slides

[[slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture-editing.pdf)] 